{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the occupation level WFH scores\n",
    "\n",
    "WFH_occ = pd.read_csv(r\"..\\Data\\Source\\occupations_workathome.csv\")\n",
    "\n",
    "WFH_occ['occ_code'] = WFH_occ['onetsoccode'].str.strip().str[:7]\n",
    "\n",
    "WFH_occ = WFH_occ.groupby('occ_code').teleworkable.agg('mean').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_SOC_xw = {\n",
    "    'Management occupation':11,\n",
    "    'Business and financial operations occupation':13,\n",
    "    'Computer and mathematical occupation':15,\n",
    "    'Architecture and engineering occupation':17,\n",
    "    'Life, physical, and social science occupation':19,\n",
    "    'Community and social service occupation':21,\n",
    "    'Legal occupation':23,\n",
    "    'Educational instruction, and library occupation':25,\n",
    "    'Arts, design, entertainment, sports, and media occupation':27,\n",
    "    'Healthcare practitioners and technical occupations':29,\n",
    "    'Health diagnosing and treating practitioners and other technical occupation':29,\n",
    "    'Health technologists and technician':29,\n",
    "    'Healthcare support occupation':31,\n",
    "    'Protective service occupations':33,\n",
    "    'Firefighting and prevention, and other protective service workers including supervisor':33,\n",
    "    'Law enforcement workers including supervisor':33,\n",
    "    'Food preparation and serving related occupation':35,\n",
    "    'Building and grounds cleaning and maintenance occupation':37,\n",
    "    'Personal care and service occupation':39,\n",
    "    'Sales and related occupation':41,\n",
    "    'Office and administrative support occupation':43,\n",
    "    'Farming, fishing, and forestry occupation':45,\n",
    "    'Construction and extraction occupation':47,\n",
    "    'Installation, maintenance, and repair occupation':49,\n",
    "    'Production occupation':51,\n",
    "    'Transportation occupation':53,\n",
    "    'Material moving occupation':53\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the occupation counts from the census\n",
    "\n",
    "census = pd.read_csv(r\"..\\Data\\Source\\ACS5_2019_S2401_03192021.csv\",\n",
    "                     skiprows=1)\n",
    "\n",
    "census = census \\\n",
    "    .drop(\n",
    "        [col for col in census.columns \\\n",
    "         if ((len(col.split(\"!!\")) <= 3) \\\n",
    "         | (\"Total\" not in col) \\\n",
    "         | (\"Estimate\" not in col)) \\\n",
    "         & (col != \"id\")], \n",
    "    axis = 1) \\\n",
    "    \n",
    "\n",
    "census.columns = ['tract'] + [string.split(\"!!\")[-1][:-1] for string in census.columns if len(string.split(\"!!\")) > 3]\n",
    "\n",
    "census['tract'] = census['tract'].str.strip().str[-11:]\n",
    "\n",
    "census = census.set_index('tract')\n",
    "\n",
    "census = census \\\n",
    "    .drop([col for col in census.columns if col not in industry_SOC_xw.keys()],\n",
    "          axis = 1)\n",
    "\n",
    "census = pd.melt(census.reset_index(), \n",
    "                 id_vars = ['tract'], \n",
    "                 value_vars = census.columns)\n",
    "\n",
    "census['cat'] = census.variable.replace(industry_SOC_xw)\n",
    "\n",
    "census = census.groupby(['tract', 'cat']).value.agg('sum').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TRACT to ZIP crosswalk file\n",
    "\n",
    "zip_tract_xw = pd.read_excel(r\"..\\Data\\Source\\ZIP_TRACT_032020.xlsx\")\n",
    "\n",
    "zip_tract_xw['ZIP'] = zip_tract_xw['ZIP'].astype(str).str.zfill(5)\n",
    "\n",
    "zip_tract_xw['TRACT'] = zip_tract_xw['TRACT'].astype(str).str.zfill(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MSA to ZIP crosswalk file\n",
    "\n",
    "zip_msa_xw = pd.read_csv(r\"..\\Data\\Intermediate\\MSA_distance.csv\") \\\n",
    "    [['CBSA', 'ZIP']]\n",
    "\n",
    "zip_msa_xw['ZIP'] = zip_msa_xw['ZIP'].astype(str).str.zfill(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the detailed occupation composition per MSA\n",
    "\n",
    "foo = pd.read_excel(r\"..\\Data\\Source\\MSA_M2019_dl.xlsx\")\n",
    "\n",
    "foo['area_title'] = foo['area_title'] \\\n",
    "    .replace({'Miami-Fort Lauderdale-West Palm Beach, FL': \"Miami-Fort Lauderdale-Pompano Beach, FL\",\n",
    "              'Atlanta-Sandy Springs-Roswell, GA': \"Atlanta-Sandy Springs-Alpharetta, GA\",\n",
    "              'Phoenix-Mesa-Scottsdale, AZ': \"Phoenix-Mesa-Chandler, AZ\",\n",
    "              'Boston-Cambridge-Nashua, MA-NH': \"Boston-Cambridge-Newton, MA-NH\",\n",
    "              'San Francisco-Oakland-Hayward, CA': \"San Francisco-Oakland-Berkeley, CA\",\n",
    "              'San Diego-Carlsbad, CA': \"San Diego-Chula Vista-Carlsbad, CA\",\n",
    "              'Sacramento--Roseville--Arden-Arcade, CA': \"Sacramento-Roseville-Folsom, CA\",\n",
    "              'Austin-Round Rock, TX': \"Austin-Round Rock-Georgetown, TX\"})\n",
    "\n",
    "foo = foo \\\n",
    "    .loc[(foo[\"jobs_1000\"] != '**') & (foo['o_group'] == 'detailed'), ['area_title', 'occ_code', 'jobs_1000']] \\\n",
    "    .merge(WFH_occ, on = 'occ_code', how = 'inner')\n",
    "\n",
    "foo['cat'] = foo['occ_code'].str.strip().str[:2].astype(int)\n",
    "foo['total'] = foo.groupby(['area_title', 'cat']).jobs_1000.transform(sum)\n",
    "foo['w_teleworkable'] = foo['jobs_1000'] * foo['teleworkable'] / foo['total']\n",
    "foo['w_teleworkable'] = foo['w_teleworkable'].astype(float)\n",
    "foo = foo \\\n",
    "    .rename(columns = {'area_title': 'CBSA'}) \\\n",
    "    .merge(zip_msa_xw, on = 'CBSA', how = 'inner') \\\n",
    "    .groupby(['ZIP', 'cat']) \\\n",
    "    .w_teleworkable.agg(sum) \\\n",
    "    .reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the tract level WFH score\n",
    "\n",
    "df = zip_tract_xw \\\n",
    "    [['ZIP', 'TRACT', 'TOT_RATIO']] \\\n",
    "    .rename(columns = {'TRACT': 'tract'}) \\\n",
    "    .merge(census, on = 'tract', how = 'inner') \\\n",
    "    .groupby(['ZIP', 'cat']) \\\n",
    "    .value.agg(sum) \\\n",
    "    .reset_index() \\\n",
    "    .merge(foo, on = ['ZIP', 'cat'], how = 'inner')\n",
    "\n",
    "df = df[df[\"value\"] > 0]\n",
    "df['w_teleworkable'] = df['value']*df['w_teleworkable']/df.groupby('ZIP').value.transform('sum')\n",
    "\n",
    "df = df \\\n",
    "    .groupby('ZIP') \\\n",
    "    .w_teleworkable.agg(sum) \\\n",
    "    .reset_index() \\\n",
    "    .rename(columns = {'w_teleworkable': 'teleworkable'})\n",
    "df[\"teleworkable\"] = df[\"teleworkable\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the file\n",
    "df \\\n",
    "    .rename(columns = {'ZIP': 'zip'}) \\\n",
    "    .to_stata(r\"..\\Data\\Intermediate\\WFH_zip.dta\", version = 119)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the MSA-level data from csv to dta\n",
    "\n",
    "cbsa_map = pd.read_excel(r\"..\\Data\\Source\\CBSAs.xls\", skiprows = 2)[:-4] \\\n",
    "    .loc[:,['CBSA Code', 'CBSA Title']] \\\n",
    "    .drop_duplicates() \\\n",
    "    .reset_index(drop = True)\n",
    "\n",
    "df_cbsa = pd.read_csv(r\"..\\Data\\Source\\MSA_workfromhome.csv\")\n",
    "df_cbsa['AREA'] = df_cbsa['AREA'].astype(str).replace('71650', '14460')\n",
    "df_cbsa \\\n",
    "    .merge(cbsa_map, left_on = 'AREA', right_on = 'CBSA Code', how = 'left') \\\n",
    "    .rename(columns = {'CBSA Title': 'cbsa', 'teleworkable_emp': 'teleworkable_cbsa'}) \\\n",
    "    [['cbsa', 'teleworkable_cbsa']] \\\n",
    "    .dropna(subset = ['cbsa']) \\\n",
    "    .to_stata(r\"..\\Data\\Intermediate\\WFH_cbsa.dta\", version = 119)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
